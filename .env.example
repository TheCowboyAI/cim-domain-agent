# AI Provider Configuration
# Copy this file to .env and fill in your API keys

# Default AI provider to use (openai, anthropic, ollama, mock)
DEFAULT_AI_PROVIDER=anthropic

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo

# Ollama Configuration (for local LLMs)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# Optional: Request timeout in seconds
AI_REQUEST_TIMEOUT=30

# Optional: Max retries for failed requests
AI_MAX_RETRIES=3
